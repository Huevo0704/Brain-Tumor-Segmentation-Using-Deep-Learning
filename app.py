# app.py

import gradio as gr
import tensorflow as tf
import numpy as np
import cv2
import os
from skimage.filters import gaussian
from skimage.segmentation import active_contour

# Giáº£ Ä‘á»‹nh file utils.py náº±m cÃ¹ng thÆ° má»¥c vÃ  Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t
from utils import (
    combined_loss, dice_coefficient, iou, sensitivity, specificity,
    segment_tumor_adaptive, calculate_final_tumor_area, calculate_evaluation_metrics
)

# --- Cáº¤U HÃŒNH VÃ€ Táº¢I MODEL ---
MODEL_PATH = "U_Net_model_attention_512.keras" # File model pháº£i náº±m cÃ¹ng thÆ° má»¥c
IMG_SIZE = 512
INCH_TO_MM = 25.4

# HÃ m táº£i model, Ä‘Æ°á»£c cache Ä‘á»ƒ chá»‰ cháº¡y má»™t láº§n khi á»©ng dá»¥ng khá»Ÿi Ä‘á»™ng
@gr.cache
def load_trained_model(path):
    """Táº£i mÃ´ hÃ¬nh Keras vá»›i cÃ¡c custom objects."""
    print("----- Äang táº£i mÃ´ hÃ¬nh... -----")
    if not os.path.exists(path):
        raise FileNotFoundError(
            f"KhÃ´ng tÃ¬m tháº¥y file model táº¡i '{path}'. "
            "HÃ£y Ä‘áº£m báº£o file model náº±m cÃ¹ng thÆ° má»¥c vá»›i app.py vÃ  báº¡n Ä‘Ã£ táº£i nÃ³ vá» báº±ng Git LFS."
        )
    custom_objects = {
        'combined_loss': combined_loss,
        'dice_coefficient': dice_coefficient, 'iou': iou,
        'sensitivity': sensitivity, 'specificity': specificity
    }
    tf.keras.mixed_precision.set_global_policy('mixed_float16')
    model = tf.keras.models.load_model(path, custom_objects=custom_objects)
    print("----- Táº£i mÃ´ hÃ¬nh thÃ nh cÃ´ng! -----")
    return model

model = load_trained_model(MODEL_PATH)

# --- HÃ€M LOGIC CHÃNH Cá»¦A DEMO ---
def process_and_compare(
    mri_image, gt_mask_image, dpi,
    median_kernel,
    adaptive_block_size, adaptive_c,
    ac_alpha, ac_beta, ac_gamma
):
    """
    HÃ m nháº­n Ä‘áº§u vÃ o tá»« giao diá»‡n, thá»±c hiá»‡n toÃ n bá»™ pipeline phÃ¢n tÃ­ch
    vÃ  tráº£ vá» káº¿t quáº£ Ä‘á»ƒ hiá»ƒn thá»‹.
    """
    if mri_image is None or gt_mask_image is None:
        return None, "Lá»—i: Vui lÃ²ng táº£i lÃªn cáº£ áº£nh MRI vÃ  áº£nh Ground Truth."

    # --- 1. Tiá»n xá»­ lÃ½ vÃ  Dá»± Ä‘oÃ¡n U-Net ---
    original_shape = mri_image.shape[:2]
    # Chuyá»ƒn Ä‘á»•i Ä‘áº§u vÃ o sang áº£nh xÃ¡m 8-bit
    image_gray = cv2.cvtColor(mri_image, cv2.COLOR_BGR2GRAY) if len(mri_image.shape) > 2 else mri_image
    gt_mask_gray = cv2.cvtColor(gt_mask_image, cv2.COLOR_BGR2GRAY) if len(gt_mask_image.shape) > 2 else gt_mask_image

    # Resize áº£nh vá» kÃ­ch thÆ°á»›c model yÃªu cáº§u
    image_resized = cv2.resize(image_gray, (IMG_SIZE, IMG_SIZE))
    gt_mask_resized = (cv2.resize(gt_mask_gray, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST) > 127).astype(np.uint8)

    # Chuáº©n bá»‹ tensor vÃ  dá»± Ä‘oÃ¡n
    input_tensor = np.expand_dims(image_resized / 255.0, axis=[0, -1]).astype(np.float32)
    pred_mask_unet = (model.predict(input_tensor)[0] > 0.5).astype(np.uint8).squeeze()
    
    if np.count_nonzero(pred_mask_unet) == 0:
        gallery_no_tumor = [(mri_image, "áº¢nh MRI Gá»‘c"), (gt_mask_image, "Ground Truth")]
        return gallery_no_tumor, "ThÃ´ng bÃ¡o: MÃ´ hÃ¬nh U-Net khÃ´ng phÃ¡t hiá»‡n tháº¥y khá»‘i u trong áº£nh nÃ y."

    # --- 2. Ãp dá»¥ng chuá»—i Háº­u xá»­ lÃ½ cÃ³ thá»ƒ tinh chá»‰nh ---
    if median_kernel % 2 == 0: median_kernel += 1 # Kernel pháº£i lÃ  sá»‘ láº»
    mask_median = (cv2.medianBlur(pred_mask_unet * 255, median_kernel) > 127).astype(np.uint8)
    
    mask_adaptive = segment_tumor_adaptive(mask_median * 255, adaptive_block_size, adaptive_c)
    
    final_mask = mask_adaptive # Báº¯t Ä‘áº§u vá»›i mask tá»« bÆ°á»›c trÆ°á»›c
    contours, _ = cv2.findContours(mask_adaptive * 255, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if contours:
        try:
            largest_contour = max(contours, key=cv2.contourArea)
            initial_snake = np.squeeze(largest_contour)
            if len(initial_snake.shape) == 2 and len(initial_snake) > 2:
                snake = active_contour(gaussian(image_resized, 1), initial_snake, 
                                       alpha=ac_alpha, beta=ac_beta, gamma=ac_gamma)
                temp_mask = np.zeros_like(final_mask); cv2.fillPoly(temp_mask, [snake.astype(np.int32)], 255)
                final_mask = (temp_mask / 255).astype(np.uint8)
        except Exception as e:
            print(f"Lá»—i Active Contour: {e}. Sá»­ dá»¥ng mask tá»« bÆ°á»›c trÆ°á»›c.")
            # Náº¿u cÃ³ lá»—i, giá»¯ nguyÃªn final_mask = mask_adaptive

    # --- 3. TÃ­nh toÃ¡n cÃ¡c Chá»‰ sá»‘ vÃ  Diá»‡n tÃ­ch ---
    iou_val, dice_val, prec_val, rec_val = calculate_evaluation_metrics(gt_mask_resized, final_mask)
    pixel_area_mm2 = (INCH_TO_MM / dpi) ** 2
    gt_geom_area, gt_pixel_area = calculate_final_tumor_area(gt_mask_resized, pixel_area_mm2)
    pred_geom_area, pred_pixel_area = calculate_final_tumor_area(final_mask, pixel_area_mm2)

    # --- 4. Chuáº©n bá»‹ káº¿t quáº£ Ä‘áº§u ra Ä‘á»ƒ hiá»ƒn thá»‹ ---
    # Táº¡o áº£nh dá»± Ä‘oÃ¡n Ä‘Ã£ tÃ´ mÃ u
    final_mask_original_size = cv2.resize(final_mask, (original_shape[1], original_shape[0]), interpolation=cv2.INTER_NEAREST)
    output_colored = cv2.cvtColor(mri_image, cv2.COLOR_GRAY2BGR) if len(mri_image.shape) < 3 else mri_image.copy()
    red_overlay = np.zeros_like(output_colored); red_overlay[final_mask_original_size == 1] = [0, 0, 255] # MÃ u Ä‘á» dáº¡ng BGR
    final_colored_image = cv2.addWeighted(output_colored, 1.0, red_overlay, 0.6, 0)
    
    # Táº¡o Gallery áº£nh Ä‘á»ƒ so sÃ¡nh
    image_gallery = [
        (mri_image, "áº¢nh MRI Gá»‘c"),
        (gt_mask_image, "Ground Truth"),
        (final_colored_image, "Dá»± Ä‘oÃ¡n cá»§a Model")
    ]
    
    # Táº¡o chuá»—i Markdown chá»©a káº¿t quáº£
    result_text = f"""
    ### Báº£ng Chá»‰ sá»‘ ÄÃ¡nh giÃ¡
    | Chá»‰ sá»‘ | GiÃ¡ trá»‹ |
    | :--- | :---: |
    | **Dice Coefficient** | `{dice_val:.4f}` |
    | **IoU (Jaccard)** | `{iou_val:.4f}` |
    | **Precision** | `{prec_val:.4f}` |
    | **Recall (Sensitivity)** | `{rec_val:.4f}` |

    ### So sÃ¡nh Diá»‡n tÃ­ch Khá»‘i u (Ä‘Æ¡n vá»‹: mmÂ²)
    | Loáº¡i diá»‡n tÃ­ch | Ground Truth | Dá»± Ä‘oÃ¡n | ChÃªnh lá»‡ch |
    | :--- | :---: | :---: | :---: |
    | **Äáº¿m Pixel** | `{gt_pixel_area:.2f}` | `{pred_pixel_area:.2f}` | `{abs(gt_pixel_area - pred_pixel_area):.2f}` |
    | **HÃ¬nh há»c** | `{gt_geom_area:.2f}` | `{pred_geom_area:.2f}` | `{abs(gt_geom_area - pred_geom_area):.2f}` |
    """
    return image_gallery, result_text

# --- Táº O GIAO DIá»†N GRADIO ---
with gr.Blocks(theme=gr.themes.Soft(), title="Demo PhÃ¢n Ä‘oáº¡n Khá»‘i u NÃ£o") as demo:
    gr.Markdown("# ðŸ”¬ Demo ÄÃ¡nh giÃ¡ vÃ  PhÃ¢n tÃ­ch MÃ´ hÃ¬nh PhÃ¢n Ä‘oáº¡n Khá»‘i u NÃ£o")
    gr.Markdown("Táº£i lÃªn áº£nh MRI vÃ  áº£nh máº·t náº¡ Ground Truth tÆ°Æ¡ng á»©ng Ä‘á»ƒ so sÃ¡nh trá»±c quan, xem cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ vÃ  phÃ¢n tÃ­ch diá»‡n tÃ­ch.")

    with gr.Row():
        with gr.Column(scale=1):
            mri_input = gr.Image(type="numpy", label="1. Táº£i áº£nh MRI")
            gt_mask_input = gr.Image(type="numpy", label="2. Táº£i áº£nh Ground Truth Mask")
            dpi_input = gr.Slider(minimum=50, maximum=600, value=96, step=1, label="DPI cá»§a áº£nh (Ä‘á»ƒ tÃ­nh mmÂ²)")
            
            with gr.Accordion("âš™ï¸ TÃ¹y chá»n Háº­u xá»­ lÃ½ (Advanced)", open=False):
                median_kernel = gr.Slider(3, 15, 5, step=2, label="Median Blur Kernel")
                adaptive_block_size = gr.Slider(3, 51, 21, step=2, label="Adaptive Threshold Block Size")
                adaptive_c = gr.Slider(1, 20, 5, label="Adaptive Threshold C Value")
                ac_alpha = gr.Slider(0.001, 0.1, 0.01, label="Active Contour Alpha (Äá»™ co dÃ£n)")
                ac_beta = gr.Slider(0.01, 1.0, 0.1, label="Active Contour Beta (Äá»™ cá»©ng)")
                ac_gamma = gr.Slider(0.001, 0.1, 0.01, label="Active Contour Gamma (Lá»±c ngoÃ i)")

            analyze_button = gr.Button("So sÃ¡nh vÃ  PhÃ¢n tÃ­ch", variant="primary")

        with gr.Column(scale=2):
            gr.Markdown("## So sÃ¡nh Trá»±c quan")
            output_gallery = gr.Gallery(label="So sÃ¡nh káº¿t quáº£", columns=3, object_fit="contain", height="auto")
            gr.Markdown("## Káº¿t quáº£ ÄÃ¡nh giÃ¡ vÃ  PhÃ¢n tÃ­ch")
            output_markdown = gr.Markdown()
    
    analyze_button.click(
        fn=process_and_compare,
        inputs=[
            mri_input, gt_mask_input, dpi_input,
            median_kernel, adaptive_block_size, adaptive_c,
            ac_alpha, ac_beta, ac_gamma
        ],
        outputs=[output_gallery, output_markdown]
    )
    
    gr.Examples(
        examples=[
            ["demo_images/demo_image_15.jpg", "demo_images/demo_gt_15.png", 96, 5, 21, 5, 0.01, 0.1, 0.01]
        ],
        inputs=[
            mri_input, gt_mask_input, dpi_input,
            median_kernel, adaptive_block_size, adaptive_c,
            ac_alpha, ac_beta, ac_gamma
        ]
    )

if __name__ == "__main__":
    demo.launch(debug=True)
